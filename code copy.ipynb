{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import msal\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load bi·∫øn m√¥i tr∆∞·ªùng\n",
    "load_dotenv()\n",
    "\n",
    "# Azure Client ID, Tenant ID, Client Secret t·ª´ file .env\n",
    "azure_client_id = os.getenv(\"AZURE_CLIENT_ID\")\n",
    "azure_tenant_id = os.getenv(\"AZURE_TENANT_ID\")\n",
    "azure_client_secret = os.getenv(\"AZURE_CLIENT_SECRET\")\n",
    "\n",
    "# SharePoint Site URL v√† ID c·ªßa Drive\n",
    "sharepoint_site_url = \"maithujsc.sharepoint.com/sites/Trainingdocument\"\n",
    "drive_id = \"b!SJpkxkt_aECkl7ZK6YMWBTM-60BFIl5ChlC_cxyDngG7XD9-vWJITZvMeqzfYkAW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_access_token():\n",
    "    \"\"\"L·∫•y token truy c·∫≠p Microsoft Graph API\"\"\"\n",
    "    app = msal.ConfidentialClientApplication(\n",
    "        azure_client_id,\n",
    "        authority=f\"https://login.microsoftonline.com/{azure_tenant_id}\",\n",
    "        client_credential=azure_client_secret\n",
    "    )\n",
    "    token = app.acquire_token_for_client(scopes=[\"https://graph.microsoft.com/.default\"])\n",
    "    return token[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_folder():\n",
    "    \"\"\"L·∫•y danh s√°ch c√°c file PDF trong th∆∞ m·ª•c\"\"\"\n",
    "    token = get_access_token()\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    \n",
    "    # URL ƒë·ªÉ l·∫•y c√°c file trong th∆∞ m·ª•c g·ªëc c·ªßa drive\n",
    "    url = f\"https://graph.microsoft.com/v1.0/drives/{drive_id}/root/children\"\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # In th√™m th√¥ng tin debug\n",
    "    print(f\"Response status code: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        files = response.json().get(\"value\", [])\n",
    "        pdf_files = [file[\"name\"] for file in files if file[\"name\"].endswith(\".pdf\")]\n",
    "        print(f\"üìÇ T√¨m th·∫•y {len(pdf_files)} file PDF:\", pdf_files)\n",
    "        return pdf_files\n",
    "    else:\n",
    "        print(\"‚ùå L·ªói l·∫•y danh s√°ch file:\", response.json())\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response status code: 200\n",
      "üìÇ T√¨m th·∫•y 5 file PDF: ['01. Mai Thu Packaging.pdf', 'Dao tao van hoa hoi nhap Mai Thu.pdf', 'H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng b·ªô app qu·∫£n l√Ω.pdf', 'H∆Ø·ªöNG D·∫™N T·∫†O CH·ªÆ K√ù EMAIL M·ªöI (1).pdf', 'Qu·∫£n l√Ω ƒë∆°n h√†ng-phi·∫øu SX - Power Apps.pdf']\n",
      "‚úÖ ƒê√£ t·∫£i file: 01. Mai Thu Packaging.pdf\n",
      "‚úÖ ƒê√£ t·∫£i file: Dao tao van hoa hoi nhap Mai Thu.pdf\n",
      "‚úÖ ƒê√£ t·∫£i file: H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng b·ªô app qu·∫£n l√Ω.pdf\n",
      "‚úÖ ƒê√£ t·∫£i file: H∆Ø·ªöNG D·∫™N T·∫†O CH·ªÆ K√ù EMAIL M·ªöI (1).pdf\n",
      "‚úÖ ƒê√£ t·∫£i file: Qu·∫£n l√Ω ƒë∆°n h√†ng-phi·∫øu SX - Power Apps.pdf\n"
     ]
    }
   ],
   "source": [
    "def download_file(file_name):\n",
    "    \"\"\"T·∫£i file PDF t·ª´ SharePoint\"\"\"\n",
    "    token = get_access_token()\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    url = f\"https://graph.microsoft.com/v1.0/drives/{drive_id}/root:/{file_name}:/content\"\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        # L∆∞u file v√†o th∆∞ m·ª•c downloads\n",
    "        with open(f\"downloads/{file_name}\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"‚úÖ ƒê√£ t·∫£i file: {file_name}\")\n",
    "    else:\n",
    "        print(f\"‚ùå L·ªói t·∫£i file {file_name}: {response.json()}\")\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c \"downloads\" n·∫øu ch∆∞a c√≥\n",
    "os.makedirs(\"downloads\", exist_ok=True)\n",
    "\n",
    "# L·∫•y danh s√°ch file PDF v√† t·∫£i xu·ªëng\n",
    "pdf_files = get_files_in_folder()\n",
    "for file in pdf_files:\n",
    "    download_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file PDF\"\"\"\n",
    "    doc = fitz.open(pdf_file)  # M·ªü file PDF\n",
    "    text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()  # Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ m·ªói trang\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# T·∫°o embedding t·ª´ vƒÉn b·∫£n\n",
    "def get_embedding(text):\n",
    "    response = openai.Embedding.create(model=\"text-embedding-ada-002\", input=text)\n",
    "    embedding = response[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    return response.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acres==0.2.0\n",
      "aiohappyeyeballs==2.4.6\n",
      "aiohttp==3.11.12\n",
      "aiosignal==1.3.2\n",
      "alembic==1.14.1\n",
      "annotated-types==0.7.0\n",
      "anyio==4.8.0\n",
      "appdirs==1.4.4\n",
      "asgiref==3.8.1\n",
      "asttokens==2.4.1\n",
      "attrs==24.3.0\n",
      "auth0-python==4.8.0\n",
      "backoff==2.2.1\n",
      "bcrypt==4.2.1\n",
      "beautifulsoup4==4.12.3\n",
      "blinker==1.9.0\n",
      "Brotli==1.1.0\n",
      "build==1.2.2.post1\n",
      "cachetools==5.5.1\n",
      "certifi==2024.12.14\n",
      "cffi==1.17.1\n",
      "charset-normalizer==3.4.1\n",
      "chroma-hnswlib==0.7.6\n",
      "chromadb==0.6.3\n",
      "ci-info==0.3.0\n",
      "clarifai==10.11.1\n",
      "clarifai-grpc==11.1.1\n",
      "clarifai-protocol==0.0.14\n",
      "click==8.1.7\n",
      "cohere==5.13.12\n",
      "colorama==0.4.6\n",
      "coloredlogs==15.0.1\n",
      "comm==0.2.2\n",
      "configobj==5.0.9\n",
      "configparser==7.1.0\n",
      "contextlib2==21.6.0\n",
      "contourpy==1.3.0\n",
      "crewai==0.102.0\n",
      "crewai-tools==0.1.6\n",
      "cryptography==44.0.1\n",
      "cycler==0.12.1\n",
      "dataclasses-json==0.6.7\n",
      "debugpy==1.8.7\n",
      "decorator==5.1.1\n",
      "defusedxml==0.7.1\n",
      "Deprecated==1.2.18\n",
      "deprecation==2.1.0\n",
      "distro==1.9.0\n",
      "docstring_parser==0.16\n",
      "durationpy==0.9\n",
      "embedchain==0.1.113\n",
      "et_xmlfile==2.0.0\n",
      "executing==2.1.0\n",
      "fastapi==0.115.8\n",
      "fastavro==1.10.0\n",
      "filelock==3.17.0\n",
      "Flask==3.1.0\n",
      "flatbuffers==25.2.10\n",
      "fonttools==4.54.1\n",
      "frozenlist==1.5.0\n",
      "fsspec==2024.6.1\n",
      "gitdb==4.0.12\n",
      "GitPython==3.1.44\n",
      "google-api-core==2.24.1\n",
      "google-auth==2.38.0\n",
      "google-cloud-aiplatform==1.80.0\n",
      "google-cloud-bigquery==3.29.0\n",
      "google-cloud-core==2.4.1\n",
      "google-cloud-resource-manager==1.14.0\n",
      "google-cloud-storage==2.19.0\n",
      "google-crc32c==1.6.0\n",
      "google-resumable-media==2.7.2\n",
      "googleapis-common-protos==1.67.0\n",
      "gptcache==0.1.44\n",
      "greenlet==3.1.1\n",
      "grpc-google-iam-v1==0.14.0\n",
      "grpcio==1.70.0\n",
      "grpcio-status==1.70.0\n",
      "h11==0.14.0\n",
      "httpcore==1.0.7\n",
      "httplib2==0.22.0\n",
      "httptools==0.6.4\n",
      "httpx==0.27.2\n",
      "httpx-sse==0.4.0\n",
      "huggingface-hub==0.28.1\n",
      "humanfriendly==10.0\n",
      "idna==3.10\n",
      "importlib_metadata==8.5.0\n",
      "importlib_resources==6.5.2\n",
      "iniconfig==2.0.0\n",
      "inquirerpy==0.3.4\n",
      "instructor==1.7.2\n",
      "ipykernel==6.29.5\n",
      "ipython==8.29.0\n",
      "isodate==0.6.1\n",
      "itsdangerous==2.2.0\n",
      "jedi==0.19.1\n",
      "Jinja2==3.1.5\n",
      "jiter==0.8.2\n",
      "json5==0.10.0\n",
      "json_repair==0.36.1\n",
      "jsonpatch==1.33\n",
      "jsonpickle==4.0.1\n",
      "jsonpointer==3.0.0\n",
      "jsonref==1.1.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2024.10.1\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "kiwisolver==1.4.7\n",
      "kubernetes==32.0.0\n",
      "lancedb==0.5.7\n",
      "langchain==0.1.13\n",
      "langchain-cohere==0.1.5\n",
      "langchain-community==0.0.29\n",
      "langchain-core==0.1.53\n",
      "langchain-openai==0.1.7\n",
      "langchain-text-splitters==0.0.2\n",
      "langsmith==0.1.147\n",
      "litellm==1.60.2\n",
      "looseversion==1.3.0\n",
      "lxml==5.3.1\n",
      "Mako==1.3.9\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==3.0.2\n",
      "marshmallow==3.26.1\n",
      "matplotlib==3.9.2\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "mmh3==5.1.0\n",
      "monotonic==1.6\n",
      "mpmath==1.3.0\n",
      "msal==1.31.1\n",
      "multidict==6.1.0\n",
      "mutagen==1.47.0\n",
      "mypy-extensions==1.0.0\n",
      "nest-asyncio==1.6.0\n",
      "networkx==3.4.2\n",
      "nibabel==5.3.2\n",
      "nodeenv==1.9.1\n",
      "numpy==1.26.4\n",
      "oauthlib==3.2.2\n",
      "onnxruntime==1.20.1\n",
      "openai==0.28.0\n",
      "opencv-python==4.10.0.84\n",
      "openpyxl==3.1.5\n",
      "opentelemetry-api==1.30.0\n",
      "opentelemetry-exporter-otlp-proto-common==1.30.0\n",
      "opentelemetry-exporter-otlp-proto-grpc==1.30.0\n",
      "opentelemetry-exporter-otlp-proto-http==1.30.0\n",
      "opentelemetry-instrumentation==0.51b0\n",
      "opentelemetry-instrumentation-asgi==0.51b0\n",
      "opentelemetry-instrumentation-fastapi==0.51b0\n",
      "opentelemetry-proto==1.30.0\n",
      "opentelemetry-sdk==1.30.0\n",
      "opentelemetry-semantic-conventions==0.51b0\n",
      "opentelemetry-util-http==0.51b0\n",
      "orjson==3.10.15\n",
      "outcome==1.3.0.post0\n",
      "overrides==7.7.0\n",
      "packaging==23.2\n",
      "pandas==2.2.3\n",
      "parso==0.8.4\n",
      "pathlib==1.0.1\n",
      "pdfminer.six==20231228\n",
      "pdfplumber==0.11.5\n",
      "pfzy==0.3.4\n",
      "pillow==11.0.0\n",
      "platformdirs==4.3.6\n",
      "pluggy==1.5.0\n",
      "posthog==3.13.0\n",
      "prompt_toolkit==3.0.48\n",
      "propcache==0.2.1\n",
      "proto-plus==1.26.0\n",
      "protobuf==5.29.3\n",
      "psutil==6.1.0\n",
      "pulsar-client==3.6.0\n",
      "pure_eval==0.2.3\n",
      "puremagic==1.28\n",
      "py==1.11.0\n",
      "pyarrow==19.0.0\n",
      "pyasn1==0.6.1\n",
      "pyasn1_modules==0.4.1\n",
      "pycparser==2.22\n",
      "pycryptodomex==3.21.0\n",
      "pydantic==2.10.6\n",
      "pydantic_core==2.27.2\n",
      "pydot==3.0.4\n",
      "pygame==2.6.1\n",
      "PyGithub==1.59.1\n",
      "Pygments==2.18.0\n",
      "PyJWT==2.10.1\n",
      "pylance==0.9.18\n",
      "PyMuPDF==1.25.3\n",
      "PyNaCl==1.5.0\n",
      "pyparsing==3.2.0\n",
      "pypdf==4.3.1\n",
      "PyPDF2==3.0.1\n",
      "pypdfium2==4.30.1\n",
      "PyPika==0.48.9\n",
      "pyproject_hooks==1.2.0\n",
      "pyreadline3==3.5.4\n",
      "pyright==1.1.394\n",
      "pysbd==0.3.4\n",
      "PySocks==1.7.1\n",
      "pytest==8.3.4\n",
      "python-dateutil==2.9.0.post0\n",
      "python-docx==1.1.2\n",
      "python-dotenv==1.0.0\n",
      "python-rapidjson==1.20\n",
      "pytube==15.0.0\n",
      "pytz==2025.1\n",
      "pyvis==0.3.2\n",
      "pywin32==308\n",
      "pyxnat==1.6.3\n",
      "PyYAML==6.0.2\n",
      "pyzmq==26.2.0\n",
      "ratelimiter==1.2.0.post0\n",
      "rdflib==6.3.2\n",
      "referencing==0.36.2\n",
      "regex==2024.11.6\n",
      "requests==2.32.3\n",
      "requests-oauthlib==2.0.0\n",
      "requests-toolbelt==1.0.0\n",
      "retry==0.9.2\n",
      "rich==13.9.4\n",
      "rpds-py==0.22.3\n",
      "rsa==4.9\n",
      "schema==0.7.5\n",
      "scipy==1.14.1\n",
      "selenium==4.27.1\n",
      "semver==3.0.4\n",
      "shapely==2.0.7\n",
      "shellingham==1.5.4\n",
      "simplejson==3.20.1\n",
      "six==1.16.0\n",
      "smmap==5.0.2\n",
      "sniffio==1.3.1\n",
      "sortedcontainers==2.4.0\n",
      "soupsieve==2.6\n",
      "SQLAlchemy==2.0.38\n",
      "stack-data==0.6.3\n",
      "starlette==0.45.3\n",
      "sympy==1.13.3\n",
      "tabulate==0.9.0\n",
      "tenacity==9.0.0\n",
      "tiktoken==0.7.0\n",
      "tokenizers==0.21.0\n",
      "tomli==2.2.1\n",
      "tomli_w==1.2.0\n",
      "tornado==6.4.1\n",
      "tqdm==4.67.1\n",
      "traitlets==5.14.3\n",
      "traits==7.0.2\n",
      "trio==0.28.0\n",
      "trio-websocket==0.11.1\n",
      "tritonclient==2.54.0\n",
      "typer==0.9.4\n",
      "types-requests==2.32.0.20241016\n",
      "typing-inspect==0.9.0\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2025.1\n",
      "urllib3==2.3.0\n",
      "uv==0.6.0\n",
      "uvicorn==0.34.0\n",
      "watchfiles==1.0.4\n",
      "wcwidth==0.2.13\n",
      "websocket-client==1.8.0\n",
      "websockets==15.0\n",
      "Werkzeug==3.1.3\n",
      "wrapt==1.17.2\n",
      "wsproto==1.2.0\n",
      "yarl==1.18.3\n",
      "youtube-transcript-api==0.6.3\n",
      "yt-dlp==2023.12.30\n",
      "zipp==3.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\tranm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip freeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\tranm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdf_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mPersistentClient(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./chroma_db\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ c∆° s·ªü d·ªØ li·ªáu\u001b[39;00m\n\u001b[0;32m      4\u001b[0m collection \u001b[38;5;241m=\u001b[39m chroma_client\u001b[38;5;241m.\u001b[39mget_or_create_collection(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_docs\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# T·∫°o collection l∆∞u t√†i li·ªáu ƒë√†o t·∫°o\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpdf_files\u001b[49m:\n\u001b[0;32m      7\u001b[0m     pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloads/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m     text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(pdf_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pdf_files' is not defined"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")  # T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ c∆° s·ªü d·ªØ li·ªáu\n",
    "collection = chroma_client.get_or_create_collection(name=\"training_docs\")  # T·∫°o collection l∆∞u t√†i li·ªáu ƒë√†o t·∫°o\n",
    "\n",
    "for file_name in pdf_files:\n",
    "    pdf_path = f\"downloads/{file_name}\"\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    if text.strip():  # Ki·ªÉm tra xem file c√≥ n·ªôi dung kh√¥ng\n",
    "        collection.add(\n",
    "            documents=[text],\n",
    "            embeddings=[get_embedding(text)],\n",
    "            ids=[file_name]\n",
    "        )\n",
    "        print(f\"‚úÖ ƒê√£ l∆∞u v√†o ChromaDB: {file_name}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è File {file_name} kh√¥ng c√≥ n·ªôi dung!\")\n",
    "        \n",
    "# Ki·ªÉm tra s·ªë l∆∞·ª£ng t√†i li·ªáu trong ChromaDB\n",
    "print(f\"üìù S·ªë l∆∞·ª£ng t√†i li·ªáu trong ChromaDB: {collection.count()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_documents_periodically():\n",
    "    \"\"\"Ki·ªÉm tra v√† t·∫£i t√†i li·ªáu m·ªõi ƒë·ªãnh k·ª≥\"\"\"\n",
    "    while True:\n",
    "        print(\"ƒêang ki·ªÉm tra t√†i li·ªáu m·ªõi t·ª´ SharePoint...\")\n",
    "        pdf_files = get_files_in_folder() \n",
    "        for file in pdf_files:\n",
    "            if file not in downloaded_files:\n",
    "                download_file(file) \n",
    "                downloaded_files.append(file)\n",
    "        time.sleep(7200)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_chromadb_with_new_documents(pdf_files):\n",
    "    \"\"\"C·∫≠p nh·∫≠t t√†i li·ªáu m·ªõi v√†o ChromaDB\"\"\"\n",
    "    for file_name in pdf_files:\n",
    "        pdf_path = f\"downloads/{file_name}\"\n",
    "        text = extract_text_from_pdf(pdf_path) \n",
    "\n",
    "        if text.strip():  \n",
    "            collection.add(\n",
    "                documents=[text],\n",
    "                embeddings=[get_embedding(text)],\n",
    "                ids=[file_name]\n",
    "            )\n",
    "            print(f\"‚úÖ ƒê√£ c·∫≠p nh·∫≠t v√†o ChromaDB: {file_name}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è File {file_name} kh√¥ng c√≥ n·ªôi dung!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_user_feedback(query, answer):\n",
    "    \"\"\"Thu th·∫≠p ph·∫£n h·ªìi t·ª´ ng∆∞·ªùi d√πng v√† l∆∞u l·∫°i v√†o file\"\"\"\n",
    "    feedback = input(\"C√¢u tr·∫£ l·ªùi n√†y c√≥ ch√≠nh x√°c kh√¥ng? (yes/no): \").lower()\n",
    "    \n",
    "    if feedback in [\"yes\", \"y\"]:\n",
    "        print(\"C·∫£m ∆°n b·∫°n!\")\n",
    "        # L∆∞u l·∫°i ph·∫£n h·ªìi ch√≠nh x√°c n·∫øu c·∫ßn (n·∫øu b·∫°n mu·ªën l∆∞u)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"C·∫£m ∆°n b·∫°n ƒë√£ ph·∫£n h·ªìi! T√¥i s·∫Ω c·∫£i thi·ªán.\")\n",
    "        # L∆∞u l·∫°i c√°c c√¢u tr·∫£ l·ªùi kh√¥ng ch√≠nh x√°c ƒë·ªÉ ph√¢n t√≠ch\n",
    "        with open(\"feedback_log.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Question: {query}, Answer: {answer}, Feedback: Incorrect\\n\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_chroma(query, top_k=3):\n",
    "    embedding = get_embedding(query)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[embedding],\n",
    "        n_results=top_k\n",
    "    )\n",
    "    \n",
    "    # Tr·∫£ v·ªÅ danh s√°ch c√°c vƒÉn b·∫£n, kh√¥ng ph·∫£i danh s√°ch con\n",
    "    return [result[0] for result in results['documents']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n vƒÉn b·∫£n t·ª´ ChromaDB\n",
    "def generate_answer(query):\n",
    "    context = \"\\n\".join(search_in_chroma(query))  # K·∫øt h·ª£p c√°c ƒëo·∫°n vƒÉn b·∫£n th√†nh m·ªôt chu·ªói\n",
    "    if context:\n",
    "        prompt = f\"Tr·∫£ l·ªùi c√¢u h·ªèi sau d·ª±a tr√™n th√¥ng tin d∆∞·ªõi ƒë√¢y:\\n\\n{context}\\n\\nC√¢u h·ªèi: {query}\\nTr·∫£ l·ªùi:\"\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Ch·ªçn m√¥ h√¨nh gpt-3.5-turbo thay v√¨ text-davinci-003\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=150\n",
    "        )\n",
    "        return response['choices'][0]['message']['content'].strip()\n",
    "    else:\n",
    "        return \"Xin l·ªói, t√¥i kh√¥ng th·ªÉ t√¨m th·∫•y th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa b·∫°n.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    print(\"Ch√†o b·∫°n! T√¥i l√† tr·ª£ l√Ω ·∫£o c·ªßa Mai Th∆∞. B·∫°n c√≥ th·ªÉ h·ªèi t√¥i b·∫•t c·ª© c√¢u h·ªèi n√†o.\")\n",
    "    while True:\n",
    "        user_input = input(\"B·∫°n: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"T·∫°m bi·ªát!\")\n",
    "            break\n",
    "\n",
    "        print(f\"\\nC√¢u h·ªèi c·ªßa b·∫°n: {user_input}\\n\")\n",
    "        answer = generate_answer(user_input) \n",
    "        \n",
    "        print(f\"Chatbot: {answer}\")\n",
    "        \n",
    "        collect_user_feedback(user_input, answer)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ch√†o b·∫°n! T√¥i l√† tr·ª£ l√Ω ·∫£o c·ªßa Mai Th∆∞. B·∫°n c√≥ th·ªÉ h·ªèi t√¥i b·∫•t c·ª© c√¢u h·ªèi n√†o.\n",
      "\n",
      "C√¢u h·ªèi c·ªßa b·∫°n: i need some informations of Take away box\n",
      "\n",
      "Chatbot: Th√¥ng tin v·ªÅ h·ªôp ƒë·ª±ng th·ª©c ƒÉn mang v·ªÅ (Take away box) bao g·ªìm:\n",
      "- V·∫≠t li·ªáu: Kraft, Ivory, gi·∫•y carton 3 l·ªõp,...\n",
      "- Tr·ªçng l∆∞·ª£ng gi·∫•y: 250gsm - 400gsm,...\n",
      "- Ph∆∞∆°ng ph√°p in: Offset / Flexo, 1 m√†u / nhi·ªÅu m√†u\n",
      "- Ki·ªÉu d√°ng: C√≥ c·ª≠a s·ªï / kh√¥ng c√≥ c·ª≠a s·ªï\n",
      "- C√°c k√≠ch th∆∞·ªõc v√† lo·∫°i h·ªôp kh√°c nhau nh∆∞ h·ªôp c·ªëc coffee mang v·ªÅ, h·ªô\n",
      "C·∫£m ∆°n b·∫°n!\n",
      "\n",
      "C√¢u h·ªèi c·ªßa b·∫°n: what about  Cup carrier tray\n",
      "\n",
      "Chatbot: Cup carrier tray is one of the products in Mai Thu's product range. It is made from white kraft and brown kraft with a paper weight of 350gsm. The printing method used for Cup carrier tray is Offset/Flexo, and it comes in a style with 2 cups or 4 cups.\n",
      "C·∫£m ∆°n b·∫°n ƒë√£ ph·∫£n h·ªìi! T√¥i s·∫Ω c·∫£i thi·ªán.\n",
      "\n",
      "C√¢u h·ªèi c·ªßa b·∫°n: and bread bag\n",
      "\n",
      "Chatbot: Bread bag.\n",
      "C·∫£m ∆°n b·∫°n ƒë√£ ph·∫£n h·ªìi! T√¥i s·∫Ω c·∫£i thi·ªán.\n",
      "\n",
      "C√¢u h·ªèi c·ªßa b·∫°n: Do mai thu packaging produce toys for kids?\n",
      "\n",
      "Chatbot: D·ª±a v√†o th√¥ng tin ƒë√£ cung c·∫•p, Mai Thu Packaging s·∫£n xu·∫•t nh·ªØng s·∫£n ph·∫©m nh∆∞ h·ªôp ƒë·ª±ng th·ª©c ƒÉn mang ƒëi, h·ªôp b√°nh pizza, t√∫i b√°nh m·ª≥, ƒë·ªì d√πng gi·∫•y v√† ph·ª• ki·ªán, ƒë·ªì ch∆°i nh√† gi·∫•y cho tr·∫ª em, nh√† cho th√∫ c∆∞ng v√† b·ªô ƒë·ªì ch∆°i d√†nh cho tr·∫ª em. V√¨ v·∫≠y, c√≥ th·ªÉ n√≥i r·∫±ng Mai Thu Packaging s·∫£n xu·∫•t ƒë·ªì ch∆°i cho tr·∫ª em.\n",
      "C·∫£m ∆°n b·∫°n ƒë√£ ph·∫£n h·ªìi! T√¥i s·∫Ω c·∫£i thi·ªán.\n",
      "\n",
      "C√¢u h·ªèi c·ªßa b·∫°n: nh·ªØng ƒë·ªì ch∆°i n√†o ƒë∆∞·ª£c s·∫£n xu·∫•t b·ªüi mai th∆∞\n",
      "\n",
      "Chatbot: C√¥ng ty C·ªï ph·∫ßn Bao B√¨ Mai Th∆∞ s·∫£n xu·∫•t c√°c s·∫£n ph·∫©m bao b√¨ gi·∫•y in offset, bao b√¨ gi·∫•y in offset b·ªìi carton, bao b√¨ gi·∫•y carton, bao b√¨ gi·∫•y cho th·ª±c ph·∫©m, s·∫£n ph·∫©m gi·∫•y g√≥i qu√†, c≈©ng nh∆∞ c√°c s·∫£n ph·∫©m c√¥ng nghi·ªáp gi·∫•y kh√°c.\n",
      "C·∫£m ∆°n b·∫°n ƒë√£ ph·∫£n h·ªìi! T√¥i s·∫Ω c·∫£i thi·ªán.\n",
      "\n",
      "C√¢u h·ªèi c·ªßa b·∫°n: li·ªát k√™  CH·∫æ ƒê·ªò PH√öC L·ª¢I\n",
      "\n",
      "Chatbot: C√¥ng ty C·ªï ph·∫ßn Bao B√¨ Mai Th∆∞ cung c·∫•p c√°c ch·∫ø ƒë·ªô ph√∫c l·ª£i nh∆∞ sau:\n",
      "\n",
      "1. Th∆∞·ªüng c√°c d·ªãp L·ªÖ l·ªõn nh∆∞ Ng√†y Qu·ªëc t·∫ø Ph·ª• n·ªØ, L·ªÖ H√πng V∆∞∆°ng, Ng√†y Qu·ªëc Kh√°nh, T·∫øt D∆∞∆°ng L·ªãch.\n",
      "2. H·ªó tr·ª£ h·ªçc tr√≤ con c·ªßa c√°n b·ªô nh√¢n vi√™n.\n",
      "3. H·ªó tr·ª£ thƒÉm h·ªèi ƒë·ªëi v·ªõi c√°c s·ª± ki·ªán nh∆∞ sinh nh·∫≠t, sinh em b√©, ·ªëm ƒëau, k·∫øt h√¥n,\n",
      "C·∫£m ∆°n b·∫°n!\n",
      "\n",
      "C√¢u h·ªèi c·ªßa b·∫°n: Li·ªát k√™ ƒë·∫ßy ƒë·ªß t·∫•t c·∫£ ph√∫c l·ª£i c·ªßa c√¥ng ty\n",
      "\n",
      "Chatbot: C√¥ng ty C·ªï ph·∫ßn Bao B√¨ Mai Th∆∞ cung c·∫•p c√°c ch√≠nh s√°ch v√† ch·∫ø ƒë·ªô ph√∫c l·ª£i sau cho nh√¢n vi√™n:\n",
      "\n",
      "1. Th∆∞·ªüng c√°c d·ªãp L·ªÖ l·ªõn nh∆∞ Ng√†y Qu·ªëc t·∫ø Ph·ª• n·ªØ 8/3, L·ªÖ H√πng V∆∞∆°ng v√† 30/04 - 01/05, L·ªÖ Qu·ªëc Kh√°nh 2/9, T·∫øt D∆∞∆°ng L·ªãch v·ªõi m·ª©c th∆∞·ªüng kh√°c nhau t√πy theo th√¢m ni√™n l√†m vi·ªác t·∫°i c√¥ng ty.\n",
      "2. H·ªó tr\n",
      "C·∫£m ∆°n b·∫°n ƒë√£ ph·∫£n h·ªìi! T√¥i s·∫Ω c·∫£i thi·ªán.\n",
      "\n",
      "C√¢u h·ªèi c·ªßa b·∫°n: g√≥i b·∫£o hi·ªÉm s·ª©c kh·ªèe c·ªßa c√¥ng ty nh∆∞ th·∫ø n√†o\n",
      "\n",
      "Chatbot: C√¥ng ty C·ªï ph·∫ßn Bao B√¨ Mai Th∆∞ c√≥ c√°c g√≥i b·∫£o hi·ªÉm s·ª©c kh·ªèe nh∆∞ sau:\n",
      "- G√≥i s·ªë 1: D√†nh cho c√°n b·ªô, c√¥ng nh√¢n vi√™n c√≥ th√¢m ni√™n t·ª´ 1 ƒë·∫øn 5 nƒÉm v·ªõi m·ª©c ph√≠ 2.556.000 VNƒê/ng∆∞·ªùi.\n",
      "- G√≥i s·ªë 2: D√†nh cho c√°n b·ªô, c√¥ng nh√¢n vi√™n c√≥ th√¢m ni√™n t·ª´ 5 ƒë·∫øn 10 nƒÉm v·ªõi m·ª©c ph√≠ 4.725.000 VNƒê/ng∆∞·ªùi.\n",
      "- G√≥i s·ªë 3: D√†nh cho c√°n b·ªô\n",
      "C·∫£m ∆°n b·∫°n ƒë√£ ph·∫£n h·ªìi! T√¥i s·∫Ω c·∫£i thi·ªán.\n",
      "T·∫°m bi·ªát!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
